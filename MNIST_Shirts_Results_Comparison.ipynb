{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f93e8766",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdd71dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8551059e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('/Users/seungwooseo/Desktop/Python/AI-IN-MEDICAL-MATERIALS/02-CNN-Convolutional-Neural-Networks/MNIST_Fashion/fashion-mnist_train.csv')\n",
    "test_data = pd.read_csv('/Users/seungwooseo/Desktop/Python/AI-IN-MEDICAL-MATERIALS/02-CNN-Convolutional-Neural-Networks/MNIST_Fashion/fashion-mnist_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab381300",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5559e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionData(Dataset):\n",
    "    \n",
    "    def __init__(self, data, transform = None):\n",
    "        self.fashion_MNIST = list(data.values)\n",
    "        self.transform = transform\n",
    "        \n",
    "        label = []\n",
    "        image = []\n",
    "        \n",
    "        for i in self.fashion_MNIST:\n",
    "            label.append(i[0])\n",
    "            image.append(i[1:])\n",
    "            \n",
    "        self.labels = np.asarray(label)\n",
    "        self.images = np.asarray(image).reshape(-1, 28, 28, 1).astype('float32') \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        label = self.labels[index]\n",
    "        image = self.images[index]\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d98e65c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = FashionData(train_data, transform=transform)\n",
    "test_set = FashionData(test_data, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47b3d815",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=600, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593e667a",
   "metadata": {},
   "source": [
    "### CNN_ReLU_SoftMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9036fe47",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiClassPerceptron(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3, 1)\n",
    "        self.fc1 = nn.Linear(5*5*16, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        X = F.relu(self.conv1(X))\n",
    "        X = F.max_pool2d(X, 2, 2)\n",
    "        X = F.relu(self.conv2(X))\n",
    "        X = F.max_pool2d(X, 2, 2)\n",
    "        X = X.view(-1, 5*5*16)\n",
    "        X = F.relu(self.fc1(X))\n",
    "        X = F.relu(self.fc2(X))\n",
    "        X = self.fc3(X)\n",
    "        return F.log_softmax(X, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c4a4eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiClassPerceptron(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "model = MultiClassPerceptron()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "632eb369",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c07139d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0  batch:   10 [  6000/60000]  loss: 1.37879682 \\ accuracy:  32.467%\n",
      "epoch:  0  batch:   20 [ 12000/60000]  loss: 0.95504701 \\ accuracy:  47.158%\n",
      "epoch:  0  batch:   30 [ 18000/60000]  loss: 0.67971492 \\ accuracy:  55.300%\n",
      "epoch:  0  batch:   40 [ 24000/60000]  loss: 0.61472809 \\ accuracy:  60.438%\n",
      "epoch:  0  batch:   50 [ 30000/60000]  loss: 0.58287525 \\ accuracy:  64.010%\n",
      "epoch:  0  batch:   60 [ 36000/60000]  loss: 0.55089504 \\ accuracy:  66.547%\n",
      "epoch:  0  batch:   70 [ 42000/60000]  loss: 0.55367190 \\ accuracy:  68.438%\n",
      "epoch:  0  batch:   80 [ 48000/60000]  loss: 0.54955930 \\ accuracy:  70.037%\n",
      "epoch:  0  batch:   90 [ 54000/60000]  loss: 0.45770544 \\ accuracy:  71.417%\n",
      "epoch:  0  batch:  100 [ 60000/60000]  loss: 0.44206715 \\ accuracy:  72.480%\n",
      "epoch:  1  batch:   10 [  6000/60000]  loss: 0.47113931 \\ accuracy:  83.100%\n",
      "epoch:  1  batch:   20 [ 12000/60000]  loss: 0.42378384 \\ accuracy:  83.708%\n",
      "epoch:  1  batch:   30 [ 18000/60000]  loss: 0.41309258 \\ accuracy:  83.961%\n",
      "epoch:  1  batch:   40 [ 24000/60000]  loss: 0.41379064 \\ accuracy:  84.013%\n",
      "epoch:  1  batch:   50 [ 30000/60000]  loss: 0.45080373 \\ accuracy:  84.153%\n",
      "epoch:  1  batch:   60 [ 36000/60000]  loss: 0.50167048 \\ accuracy:  84.183%\n",
      "epoch:  1  batch:   70 [ 42000/60000]  loss: 0.46807516 \\ accuracy:  84.212%\n",
      "epoch:  1  batch:   80 [ 48000/60000]  loss: 0.41570109 \\ accuracy:  84.244%\n",
      "epoch:  1  batch:   90 [ 54000/60000]  loss: 0.41598952 \\ accuracy:  84.343%\n",
      "epoch:  1  batch:  100 [ 60000/60000]  loss: 0.37235633 \\ accuracy:  84.450%\n",
      "epoch:  2  batch:   10 [  6000/60000]  loss: 0.36428615 \\ accuracy:  85.450%\n",
      "epoch:  2  batch:   20 [ 12000/60000]  loss: 0.38427556 \\ accuracy:  85.958%\n",
      "epoch:  2  batch:   30 [ 18000/60000]  loss: 0.35036555 \\ accuracy:  86.061%\n",
      "epoch:  2  batch:   40 [ 24000/60000]  loss: 0.37168038 \\ accuracy:  86.108%\n",
      "epoch:  2  batch:   50 [ 30000/60000]  loss: 0.33351514 \\ accuracy:  86.240%\n",
      "epoch:  2  batch:   60 [ 36000/60000]  loss: 0.35032049 \\ accuracy:  86.206%\n",
      "epoch:  2  batch:   70 [ 42000/60000]  loss: 0.37215450 \\ accuracy:  86.219%\n",
      "epoch:  2  batch:   80 [ 48000/60000]  loss: 0.35743880 \\ accuracy:  86.112%\n",
      "epoch:  2  batch:   90 [ 54000/60000]  loss: 0.39068159 \\ accuracy:  86.191%\n",
      "epoch:  2  batch:  100 [ 60000/60000]  loss: 0.36464876 \\ accuracy:  86.335%\n",
      "epoch:  3  batch:   10 [  6000/60000]  loss: 0.40543920 \\ accuracy:  87.483%\n",
      "epoch:  3  batch:   20 [ 12000/60000]  loss: 0.31116802 \\ accuracy:  87.233%\n",
      "epoch:  3  batch:   30 [ 18000/60000]  loss: 0.31033680 \\ accuracy:  87.272%\n",
      "epoch:  3  batch:   40 [ 24000/60000]  loss: 0.34022331 \\ accuracy:  87.263%\n",
      "epoch:  3  batch:   50 [ 30000/60000]  loss: 0.33256140 \\ accuracy:  87.457%\n",
      "epoch:  3  batch:   60 [ 36000/60000]  loss: 0.35633650 \\ accuracy:  87.503%\n",
      "epoch:  3  batch:   70 [ 42000/60000]  loss: 0.32146394 \\ accuracy:  87.581%\n",
      "epoch:  3  batch:   80 [ 48000/60000]  loss: 0.45346999 \\ accuracy:  87.517%\n",
      "epoch:  3  batch:   90 [ 54000/60000]  loss: 0.36575338 \\ accuracy:  87.533%\n",
      "epoch:  3  batch:  100 [ 60000/60000]  loss: 0.32013455 \\ accuracy:  87.558%\n",
      "epoch:  4  batch:   10 [  6000/60000]  loss: 0.30482638 \\ accuracy:  88.200%\n",
      "epoch:  4  batch:   20 [ 12000/60000]  loss: 0.32598031 \\ accuracy:  88.392%\n",
      "epoch:  4  batch:   30 [ 18000/60000]  loss: 0.29353422 \\ accuracy:  88.278%\n",
      "epoch:  4  batch:   40 [ 24000/60000]  loss: 0.33904928 \\ accuracy:  88.296%\n",
      "epoch:  4  batch:   50 [ 30000/60000]  loss: 0.35093680 \\ accuracy:  88.317%\n",
      "epoch:  4  batch:   60 [ 36000/60000]  loss: 0.35903859 \\ accuracy:  88.403%\n",
      "epoch:  4  batch:   70 [ 42000/60000]  loss: 0.31643280 \\ accuracy:  88.319%\n",
      "epoch:  4  batch:   80 [ 48000/60000]  loss: 0.32219818 \\ accuracy:  88.329%\n",
      "epoch:  4  batch:   90 [ 54000/60000]  loss: 0.34951290 \\ accuracy:  88.335%\n",
      "epoch:  4  batch:  100 [ 60000/60000]  loss: 0.36617434 \\ accuracy:  88.302%\n",
      "epoch:  5  batch:   10 [  6000/60000]  loss: 0.31375962 \\ accuracy:  88.517%\n",
      "epoch:  5  batch:   20 [ 12000/60000]  loss: 0.31834236 \\ accuracy:  88.458%\n",
      "epoch:  5  batch:   30 [ 18000/60000]  loss: 0.26606354 \\ accuracy:  88.494%\n",
      "epoch:  5  batch:   40 [ 24000/60000]  loss: 0.26445487 \\ accuracy:  88.571%\n",
      "epoch:  5  batch:   50 [ 30000/60000]  loss: 0.31165826 \\ accuracy:  88.710%\n",
      "epoch:  5  batch:   60 [ 36000/60000]  loss: 0.32796606 \\ accuracy:  88.686%\n",
      "epoch:  5  batch:   70 [ 42000/60000]  loss: 0.29820552 \\ accuracy:  88.752%\n",
      "epoch:  5  batch:   80 [ 48000/60000]  loss: 0.35106590 \\ accuracy:  88.731%\n",
      "epoch:  5  batch:   90 [ 54000/60000]  loss: 0.32691336 \\ accuracy:  88.680%\n",
      "epoch:  5  batch:  100 [ 60000/60000]  loss: 0.32176268 \\ accuracy:  88.695%\n",
      "epoch:  6  batch:   10 [  6000/60000]  loss: 0.33385879 \\ accuracy:  88.483%\n",
      "epoch:  6  batch:   20 [ 12000/60000]  loss: 0.26557514 \\ accuracy:  88.658%\n",
      "epoch:  6  batch:   30 [ 18000/60000]  loss: 0.28681099 \\ accuracy:  88.900%\n",
      "epoch:  6  batch:   40 [ 24000/60000]  loss: 0.29120502 \\ accuracy:  89.088%\n",
      "epoch:  6  batch:   50 [ 30000/60000]  loss: 0.28605369 \\ accuracy:  89.223%\n",
      "epoch:  6  batch:   60 [ 36000/60000]  loss: 0.24384657 \\ accuracy:  89.328%\n",
      "epoch:  6  batch:   70 [ 42000/60000]  loss: 0.29790810 \\ accuracy:  89.481%\n",
      "epoch:  6  batch:   80 [ 48000/60000]  loss: 0.27471682 \\ accuracy:  89.431%\n",
      "epoch:  6  batch:   90 [ 54000/60000]  loss: 0.29409385 \\ accuracy:  89.398%\n",
      "epoch:  6  batch:  100 [ 60000/60000]  loss: 0.28188115 \\ accuracy:  89.350%\n",
      "epoch:  7  batch:   10 [  6000/60000]  loss: 0.22964568 \\ accuracy:  89.833%\n",
      "epoch:  7  batch:   20 [ 12000/60000]  loss: 0.30397785 \\ accuracy:  90.333%\n",
      "epoch:  7  batch:   30 [ 18000/60000]  loss: 0.29454014 \\ accuracy:  90.183%\n",
      "epoch:  7  batch:   40 [ 24000/60000]  loss: 0.25370055 \\ accuracy:  90.154%\n",
      "epoch:  7  batch:   50 [ 30000/60000]  loss: 0.31345263 \\ accuracy:  89.957%\n",
      "epoch:  7  batch:   60 [ 36000/60000]  loss: 0.31482184 \\ accuracy:  89.669%\n",
      "epoch:  7  batch:   70 [ 42000/60000]  loss: 0.31251401 \\ accuracy:  89.610%\n",
      "epoch:  7  batch:   80 [ 48000/60000]  loss: 0.25090918 \\ accuracy:  89.612%\n",
      "epoch:  7  batch:   90 [ 54000/60000]  loss: 0.24565722 \\ accuracy:  89.759%\n",
      "epoch:  7  batch:  100 [ 60000/60000]  loss: 0.26433891 \\ accuracy:  89.737%\n",
      "epoch:  8  batch:   10 [  6000/60000]  loss: 0.27787140 \\ accuracy:  89.817%\n",
      "epoch:  8  batch:   20 [ 12000/60000]  loss: 0.22036311 \\ accuracy:  90.000%\n",
      "epoch:  8  batch:   30 [ 18000/60000]  loss: 0.29584101 \\ accuracy:  89.861%\n",
      "epoch:  8  batch:   40 [ 24000/60000]  loss: 0.27782527 \\ accuracy:  89.858%\n",
      "epoch:  8  batch:   50 [ 30000/60000]  loss: 0.25430825 \\ accuracy:  90.017%\n",
      "epoch:  8  batch:   60 [ 36000/60000]  loss: 0.24534510 \\ accuracy:  89.975%\n",
      "epoch:  8  batch:   70 [ 42000/60000]  loss: 0.29257175 \\ accuracy:  90.060%\n",
      "epoch:  8  batch:   80 [ 48000/60000]  loss: 0.25274208 \\ accuracy:  90.044%\n",
      "epoch:  8  batch:   90 [ 54000/60000]  loss: 0.28651038 \\ accuracy:  89.993%\n",
      "epoch:  8  batch:  100 [ 60000/60000]  loss: 0.25168559 \\ accuracy:  90.032%\n",
      "epoch:  9  batch:   10 [  6000/60000]  loss: 0.19128466 \\ accuracy:  91.550%\n",
      "epoch:  9  batch:   20 [ 12000/60000]  loss: 0.26612186 \\ accuracy:  90.992%\n",
      "epoch:  9  batch:   30 [ 18000/60000]  loss: 0.23553391 \\ accuracy:  90.600%\n",
      "epoch:  9  batch:   40 [ 24000/60000]  loss: 0.27459556 \\ accuracy:  90.558%\n",
      "epoch:  9  batch:   50 [ 30000/60000]  loss: 0.27021348 \\ accuracy:  90.467%\n",
      "epoch:  9  batch:   60 [ 36000/60000]  loss: 0.27381212 \\ accuracy:  90.525%\n",
      "epoch:  9  batch:   70 [ 42000/60000]  loss: 0.28301820 \\ accuracy:  90.545%\n",
      "epoch:  9  batch:   80 [ 48000/60000]  loss: 0.28749630 \\ accuracy:  90.494%\n",
      "epoch:  9  batch:   90 [ 54000/60000]  loss: 0.27192771 \\ accuracy:  90.378%\n",
      "epoch:  9  batch:  100 [ 60000/60000]  loss: 0.28663915 \\ accuracy:  90.350%\n",
      "\n",
      "Duration: 100 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "epochs = 10\n",
    "trn_losses = []\n",
    "tst_losses = []\n",
    "trn_correct = []\n",
    "tst_correct =[]\n",
    "\n",
    "for i in range(epochs):\n",
    "    \n",
    "    trn_corr = 0\n",
    "    tst_corr = 0\n",
    "    \n",
    "    for b, (X_train, y_train) in enumerate(train_loader):\n",
    "        b+=1\n",
    "        \n",
    "        y_pred = model(X_train)\n",
    "        loss = criterion(y_pred, y_train)\n",
    "        \n",
    "        predicted = torch.max(y_pred.data, 1)[1]\n",
    "        batch_corr = (predicted == y_train).sum()\n",
    "        trn_corr += batch_corr\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if b%10 == 0:\n",
    "            print(f'epoch: {i:2}  batch: {b:4} [{600*b:6}/60000]  loss: {loss.item():10.8f} \\ accuracy: {trn_corr.item()*100/(600*b):7.3f}%')\n",
    "            \n",
    "    trn_losses.append(loss.item())\n",
    "    trn_correct.append(trn_corr.item())\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for b, (X_test, y_test) in enumerate(test_loader):\n",
    "            \n",
    "            y_val = model(X_test)\n",
    "            \n",
    "            predicted = torch.max(y_val.data, 1)[1]\n",
    "            tst_corr += (predicted == y_test).sum()\n",
    "            \n",
    "    \n",
    "    loss = criterion(y_val, y_test)\n",
    "    tst_losses.append(loss)\n",
    "    tst_correct.append(tst_corr)\n",
    "    \n",
    "\n",
    "print(f'\\nDuration: {time.time() - start_time:.0f} seconds') # print the time elapsed            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bcddfb",
   "metadata": {},
   "source": [
    "#### Time: 100 Seconds / Accuracy: 90.35%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8398bd5",
   "metadata": {},
   "source": [
    "### CNN_Tanh_Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4f5b2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiClassPerceptron_Tanh(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1_T = nn.Conv2d(1, 6, 3, 1)\n",
    "        self.conv2_T = nn.Conv2d(6, 16, 3, 1)\n",
    "        self.fc1_T = nn.Linear(5*5*16, 120)\n",
    "        self.fc2_T = nn.Linear(120, 84)\n",
    "        self.fc3_T = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        X = torch.tanh(self.conv1_T(X))\n",
    "        X = F.max_pool2d(X, 2, 2)\n",
    "        X = torch.tanh(self.conv2_T(X))\n",
    "        X = F.max_pool2d(X, 2, 2)\n",
    "        X = X.view(-1, 5*5*16)\n",
    "        X = F.relu(self.fc1_T(X))\n",
    "        X = F.relu(self.fc2_T(X))\n",
    "        X = self.fc3_T(X)\n",
    "        return F.sigmoid(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5262f2fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiClassPerceptron_Tanh(\n",
       "  (conv1_T): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2_T): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1_T): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2_T): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3_T): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(22)\n",
    "model_tanh = MultiClassPerceptron_Tanh()\n",
    "model_tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d2af093",
   "metadata": {},
   "outputs": [],
   "source": [
    "tanh_criterion = nn.CrossEntropyLoss()\n",
    "tanh_optimizer = torch.optim.Adam(model_tanh.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41b6f26a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/pytorchenv/lib/python3.8/site-packages/torch/nn/functional.py:1805: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0  batch:   10 [  6000/60000]  loss: 2.23697138 \\ accuracy:  31.950%\n",
      "epoch:  0  batch:   20 [ 12000/60000]  loss: 2.03798485 \\ accuracy:  41.908%\n",
      "epoch:  0  batch:   30 [ 18000/60000]  loss: 1.86863792 \\ accuracy:  45.533%\n",
      "epoch:  0  batch:   40 [ 24000/60000]  loss: 1.78770447 \\ accuracy:  45.746%\n",
      "epoch:  0  batch:   50 [ 30000/60000]  loss: 1.78253353 \\ accuracy:  45.813%\n",
      "epoch:  0  batch:   60 [ 36000/60000]  loss: 1.74913371 \\ accuracy:  45.994%\n",
      "epoch:  0  batch:   70 [ 42000/60000]  loss: 1.71817338 \\ accuracy:  46.388%\n",
      "epoch:  0  batch:   80 [ 48000/60000]  loss: 1.72578454 \\ accuracy:  46.944%\n",
      "epoch:  0  batch:   90 [ 54000/60000]  loss: 1.69708025 \\ accuracy:  48.039%\n",
      "epoch:  0  batch:  100 [ 60000/60000]  loss: 1.70152164 \\ accuracy:  49.060%\n",
      "epoch:  1  batch:   10 [  6000/60000]  loss: 1.68664443 \\ accuracy:  60.017%\n",
      "epoch:  1  batch:   20 [ 12000/60000]  loss: 1.68907177 \\ accuracy:  59.508%\n",
      "epoch:  1  batch:   30 [ 18000/60000]  loss: 1.67280805 \\ accuracy:  60.056%\n",
      "epoch:  1  batch:   40 [ 24000/60000]  loss: 1.66083241 \\ accuracy:  60.621%\n",
      "epoch:  1  batch:   50 [ 30000/60000]  loss: 1.67907870 \\ accuracy:  60.900%\n",
      "epoch:  1  batch:   60 [ 36000/60000]  loss: 1.63566840 \\ accuracy:  61.242%\n",
      "epoch:  1  batch:   70 [ 42000/60000]  loss: 1.66682327 \\ accuracy:  61.338%\n",
      "epoch:  1  batch:   80 [ 48000/60000]  loss: 1.64091873 \\ accuracy:  61.554%\n",
      "epoch:  1  batch:   90 [ 54000/60000]  loss: 1.62734115 \\ accuracy:  61.826%\n",
      "epoch:  1  batch:  100 [ 60000/60000]  loss: 1.63969696 \\ accuracy:  61.908%\n",
      "epoch:  2  batch:   10 [  6000/60000]  loss: 1.62590230 \\ accuracy:  63.417%\n",
      "epoch:  2  batch:   20 [ 12000/60000]  loss: 1.65573621 \\ accuracy:  63.308%\n",
      "epoch:  2  batch:   30 [ 18000/60000]  loss: 1.63352108 \\ accuracy:  63.722%\n",
      "epoch:  2  batch:   40 [ 24000/60000]  loss: 1.62109435 \\ accuracy:  64.092%\n",
      "epoch:  2  batch:   50 [ 30000/60000]  loss: 1.61590230 \\ accuracy:  64.230%\n",
      "epoch:  2  batch:   60 [ 36000/60000]  loss: 1.63183415 \\ accuracy:  64.272%\n",
      "epoch:  2  batch:   70 [ 42000/60000]  loss: 1.63262463 \\ accuracy:  64.431%\n",
      "epoch:  2  batch:   80 [ 48000/60000]  loss: 1.61945093 \\ accuracy:  64.702%\n",
      "epoch:  2  batch:   90 [ 54000/60000]  loss: 1.62920153 \\ accuracy:  64.913%\n",
      "epoch:  2  batch:  100 [ 60000/60000]  loss: 1.61329675 \\ accuracy:  65.167%\n",
      "epoch:  3  batch:   10 [  6000/60000]  loss: 1.62000036 \\ accuracy:  68.067%\n",
      "epoch:  3  batch:   20 [ 12000/60000]  loss: 1.59367895 \\ accuracy:  68.417%\n",
      "epoch:  3  batch:   30 [ 18000/60000]  loss: 1.60763574 \\ accuracy:  68.522%\n",
      "epoch:  3  batch:   40 [ 24000/60000]  loss: 1.60475779 \\ accuracy:  68.450%\n",
      "epoch:  3  batch:   50 [ 30000/60000]  loss: 1.60967135 \\ accuracy:  68.660%\n",
      "epoch:  3  batch:   60 [ 36000/60000]  loss: 1.60759008 \\ accuracy:  68.653%\n",
      "epoch:  3  batch:   70 [ 42000/60000]  loss: 1.60806274 \\ accuracy:  68.679%\n",
      "epoch:  3  batch:   80 [ 48000/60000]  loss: 1.59416354 \\ accuracy:  68.758%\n",
      "epoch:  3  batch:   90 [ 54000/60000]  loss: 1.59371948 \\ accuracy:  68.933%\n",
      "epoch:  3  batch:  100 [ 60000/60000]  loss: 1.60882044 \\ accuracy:  69.165%\n",
      "epoch:  4  batch:   10 [  6000/60000]  loss: 1.60011995 \\ accuracy:  71.767%\n",
      "epoch:  4  batch:   20 [ 12000/60000]  loss: 1.60562944 \\ accuracy:  70.942%\n",
      "epoch:  4  batch:   30 [ 18000/60000]  loss: 1.60327578 \\ accuracy:  71.494%\n",
      "epoch:  4  batch:   40 [ 24000/60000]  loss: 1.59185147 \\ accuracy:  71.796%\n",
      "epoch:  4  batch:   50 [ 30000/60000]  loss: 1.60394466 \\ accuracy:  71.907%\n",
      "epoch:  4  batch:   60 [ 36000/60000]  loss: 1.60042095 \\ accuracy:  72.408%\n",
      "epoch:  4  batch:   70 [ 42000/60000]  loss: 1.59208667 \\ accuracy:  72.412%\n",
      "epoch:  4  batch:   80 [ 48000/60000]  loss: 1.60670519 \\ accuracy:  72.502%\n",
      "epoch:  4  batch:   90 [ 54000/60000]  loss: 1.59721923 \\ accuracy:  72.946%\n",
      "epoch:  4  batch:  100 [ 60000/60000]  loss: 1.59963286 \\ accuracy:  73.045%\n",
      "epoch:  5  batch:   10 [  6000/60000]  loss: 1.59795988 \\ accuracy:  76.000%\n",
      "epoch:  5  batch:   20 [ 12000/60000]  loss: 1.58779824 \\ accuracy:  75.350%\n",
      "epoch:  5  batch:   30 [ 18000/60000]  loss: 1.58808553 \\ accuracy:  75.350%\n",
      "epoch:  5  batch:   40 [ 24000/60000]  loss: 1.59035110 \\ accuracy:  75.254%\n",
      "epoch:  5  batch:   50 [ 30000/60000]  loss: 1.60458767 \\ accuracy:  75.187%\n",
      "epoch:  5  batch:   60 [ 36000/60000]  loss: 1.58731937 \\ accuracy:  75.225%\n",
      "epoch:  5  batch:   70 [ 42000/60000]  loss: 1.58545792 \\ accuracy:  75.386%\n",
      "epoch:  5  batch:   80 [ 48000/60000]  loss: 1.60003459 \\ accuracy:  75.494%\n",
      "epoch:  5  batch:   90 [ 54000/60000]  loss: 1.58610749 \\ accuracy:  75.631%\n",
      "epoch:  5  batch:  100 [ 60000/60000]  loss: 1.58100235 \\ accuracy:  75.757%\n",
      "epoch:  6  batch:   10 [  6000/60000]  loss: 1.58815730 \\ accuracy:  79.750%\n",
      "epoch:  6  batch:   20 [ 12000/60000]  loss: 1.57240391 \\ accuracy:  79.183%\n",
      "epoch:  6  batch:   30 [ 18000/60000]  loss: 1.58172250 \\ accuracy:  78.650%\n",
      "epoch:  6  batch:   40 [ 24000/60000]  loss: 1.60195231 \\ accuracy:  78.612%\n",
      "epoch:  6  batch:   50 [ 30000/60000]  loss: 1.58404768 \\ accuracy:  78.843%\n",
      "epoch:  6  batch:   60 [ 36000/60000]  loss: 1.58253610 \\ accuracy:  78.839%\n",
      "epoch:  6  batch:   70 [ 42000/60000]  loss: 1.57274830 \\ accuracy:  78.840%\n",
      "epoch:  6  batch:   80 [ 48000/60000]  loss: 1.57783782 \\ accuracy:  78.835%\n",
      "epoch:  6  batch:   90 [ 54000/60000]  loss: 1.57067239 \\ accuracy:  78.839%\n",
      "epoch:  6  batch:  100 [ 60000/60000]  loss: 1.58827615 \\ accuracy:  78.870%\n",
      "epoch:  7  batch:   10 [  6000/60000]  loss: 1.57631373 \\ accuracy:  79.367%\n",
      "epoch:  7  batch:   20 [ 12000/60000]  loss: 1.59075224 \\ accuracy:  79.367%\n",
      "epoch:  7  batch:   30 [ 18000/60000]  loss: 1.57537806 \\ accuracy:  79.317%\n",
      "epoch:  7  batch:   40 [ 24000/60000]  loss: 1.56745839 \\ accuracy:  79.550%\n",
      "epoch:  7  batch:   50 [ 30000/60000]  loss: 1.56693232 \\ accuracy:  79.760%\n",
      "epoch:  7  batch:   60 [ 36000/60000]  loss: 1.58377576 \\ accuracy:  79.664%\n",
      "epoch:  7  batch:   70 [ 42000/60000]  loss: 1.57310283 \\ accuracy:  79.645%\n",
      "epoch:  7  batch:   80 [ 48000/60000]  loss: 1.57247078 \\ accuracy:  79.642%\n",
      "epoch:  7  batch:   90 [ 54000/60000]  loss: 1.57734644 \\ accuracy:  79.720%\n",
      "epoch:  7  batch:  100 [ 60000/60000]  loss: 1.57837307 \\ accuracy:  79.698%\n",
      "epoch:  8  batch:   10 [  6000/60000]  loss: 1.57254338 \\ accuracy:  80.367%\n",
      "epoch:  8  batch:   20 [ 12000/60000]  loss: 1.57259166 \\ accuracy:  80.858%\n",
      "epoch:  8  batch:   30 [ 18000/60000]  loss: 1.57540071 \\ accuracy:  80.467%\n",
      "epoch:  8  batch:   40 [ 24000/60000]  loss: 1.58068168 \\ accuracy:  80.246%\n",
      "epoch:  8  batch:   50 [ 30000/60000]  loss: 1.57526720 \\ accuracy:  80.047%\n",
      "epoch:  8  batch:   60 [ 36000/60000]  loss: 1.57352686 \\ accuracy:  80.083%\n",
      "epoch:  8  batch:   70 [ 42000/60000]  loss: 1.55793273 \\ accuracy:  80.160%\n",
      "epoch:  8  batch:   80 [ 48000/60000]  loss: 1.56469488 \\ accuracy:  80.227%\n",
      "epoch:  8  batch:   90 [ 54000/60000]  loss: 1.55958605 \\ accuracy:  80.369%\n",
      "epoch:  8  batch:  100 [ 60000/60000]  loss: 1.57724464 \\ accuracy:  80.428%\n",
      "epoch:  9  batch:   10 [  6000/60000]  loss: 1.57071936 \\ accuracy:  80.950%\n",
      "epoch:  9  batch:   20 [ 12000/60000]  loss: 1.56263208 \\ accuracy:  80.942%\n",
      "epoch:  9  batch:   30 [ 18000/60000]  loss: 1.57376122 \\ accuracy:  81.028%\n",
      "epoch:  9  batch:   40 [ 24000/60000]  loss: 1.56492770 \\ accuracy:  81.200%\n",
      "epoch:  9  batch:   50 [ 30000/60000]  loss: 1.55575311 \\ accuracy:  80.987%\n",
      "epoch:  9  batch:   60 [ 36000/60000]  loss: 1.54993784 \\ accuracy:  80.933%\n",
      "epoch:  9  batch:   70 [ 42000/60000]  loss: 1.57610273 \\ accuracy:  80.914%\n",
      "epoch:  9  batch:   80 [ 48000/60000]  loss: 1.57385445 \\ accuracy:  80.817%\n",
      "epoch:  9  batch:   90 [ 54000/60000]  loss: 1.57515848 \\ accuracy:  80.756%\n",
      "epoch:  9  batch:  100 [ 60000/60000]  loss: 1.57199144 \\ accuracy:  80.785%\n",
      "\n",
      "Duration: 102 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "epochs = 10\n",
    "tanh_trn_losses = []\n",
    "tanh_tst_losses = []\n",
    "tanh_trn_correct = []\n",
    "tanh_tst_correct =[]\n",
    "\n",
    "for i in range(epochs):\n",
    "    \n",
    "    trn_corr = 0\n",
    "    tst_corr = 0\n",
    "    \n",
    "    for b, (X_train, y_train) in enumerate(train_loader):\n",
    "        b+=1\n",
    "        \n",
    "        y_pred = model_tanh(X_train)\n",
    "        loss = tanh_criterion(y_pred, y_train)\n",
    "        \n",
    "        predicted = torch.max(y_pred.data, 1)[1]\n",
    "        batch_corr = (predicted == y_train).sum()\n",
    "        trn_corr += batch_corr\n",
    "        \n",
    "        tanh_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        tanh_optimizer.step()\n",
    "        \n",
    "        if b%10 == 0:\n",
    "            print(f'epoch: {i:2}  batch: {b:4} [{600*b:6}/60000]  loss: {loss.item():10.8f} \\ accuracy: {trn_corr.item()*100/(600*b):7.3f}%')\n",
    "            \n",
    "    tanh_trn_losses.append(loss.item())\n",
    "    tanh_trn_correct.append(trn_corr.item())\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for b, (X_test, y_test) in enumerate(test_loader):\n",
    "            \n",
    "            y_val = model_tanh(X_test)\n",
    "            \n",
    "            predicted = torch.max(y_val.data, 1)[1]\n",
    "            tst_corr += (predicted == y_test).sum()\n",
    "            \n",
    "    \n",
    "    loss = tanh_criterion(y_val, y_test)\n",
    "    tanh_tst_losses.append(loss)\n",
    "    tanh_tst_correct.append(tst_corr)\n",
    "    \n",
    "\n",
    "print(f'\\nDuration: {time.time() - start_time:.0f} seconds') # print the time elapsed            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ce2c77",
   "metadata": {},
   "source": [
    "#### Time: 102 Seconds / Accuracy: 80.785%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333c7dab",
   "metadata": {},
   "source": [
    "### CNN_Tanh_SoftMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "670efb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiClassPerceptron_Tanh_SM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3, 1)\n",
    "        self.fc1 = nn.Linear(5*5*16, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        X = torch.tanh(self.conv1(X))\n",
    "        X = F.max_pool2d(X, 2, 2)\n",
    "        X = torch.tanh(self.conv2(X))\n",
    "        X = F.max_pool2d(X, 2, 2)\n",
    "        X = X.view(-1, 5*5*16)\n",
    "        X = F.relu(self.fc1(X))\n",
    "        X = F.relu(self.fc2(X))\n",
    "        X = self.fc3(X)\n",
    "        return F.log_softmax(X, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d05a259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiClassPerceptron_Tanh_SM(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(22)\n",
    "model_tanh_SM = MultiClassPerceptron_Tanh_SM()\n",
    "model_tanh_SM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdf89444",
   "metadata": {},
   "outputs": [],
   "source": [
    "tanh_SM_criterion = nn.CrossEntropyLoss()\n",
    "tanh_SM_optimizer = torch.optim.Adam(model_tanh_SM.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "495b8b43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0  batch:   10 [  6000/60000]  loss: 2.05739188 \\ accuracy:  34.733%\n",
      "epoch:  0  batch:   20 [ 12000/60000]  loss: 1.44330263 \\ accuracy:  45.875%\n",
      "epoch:  0  batch:   30 [ 18000/60000]  loss: 1.04534376 \\ accuracy:  51.239%\n",
      "epoch:  0  batch:   40 [ 24000/60000]  loss: 0.79805136 \\ accuracy:  54.917%\n",
      "epoch:  0  batch:   50 [ 30000/60000]  loss: 0.83621693 \\ accuracy:  57.633%\n",
      "epoch:  0  batch:   60 [ 36000/60000]  loss: 0.75412875 \\ accuracy:  59.853%\n",
      "epoch:  0  batch:   70 [ 42000/60000]  loss: 0.62224966 \\ accuracy:  61.795%\n",
      "epoch:  0  batch:   80 [ 48000/60000]  loss: 0.65670025 \\ accuracy:  63.144%\n",
      "epoch:  0  batch:   90 [ 54000/60000]  loss: 0.60951126 \\ accuracy:  64.572%\n",
      "epoch:  0  batch:  100 [ 60000/60000]  loss: 0.64463162 \\ accuracy:  65.672%\n",
      "epoch:  1  batch:   10 [  6000/60000]  loss: 0.60726339 \\ accuracy:  76.067%\n",
      "epoch:  1  batch:   20 [ 12000/60000]  loss: 0.63884711 \\ accuracy:  76.408%\n",
      "epoch:  1  batch:   30 [ 18000/60000]  loss: 0.57683945 \\ accuracy:  76.561%\n",
      "epoch:  1  batch:   40 [ 24000/60000]  loss: 0.54291731 \\ accuracy:  77.013%\n",
      "epoch:  1  batch:   50 [ 30000/60000]  loss: 0.58462650 \\ accuracy:  77.460%\n",
      "epoch:  1  batch:   60 [ 36000/60000]  loss: 0.48449203 \\ accuracy:  77.917%\n",
      "epoch:  1  batch:   70 [ 42000/60000]  loss: 0.57697207 \\ accuracy:  78.183%\n",
      "epoch:  1  batch:   80 [ 48000/60000]  loss: 0.50684226 \\ accuracy:  78.444%\n",
      "epoch:  1  batch:   90 [ 54000/60000]  loss: 0.44413784 \\ accuracy:  78.676%\n",
      "epoch:  1  batch:  100 [ 60000/60000]  loss: 0.52170527 \\ accuracy:  78.917%\n",
      "epoch:  2  batch:   10 [  6000/60000]  loss: 0.43009588 \\ accuracy:  81.450%\n",
      "epoch:  2  batch:   20 [ 12000/60000]  loss: 0.55487943 \\ accuracy:  81.650%\n",
      "epoch:  2  batch:   30 [ 18000/60000]  loss: 0.50659204 \\ accuracy:  82.050%\n",
      "epoch:  2  batch:   40 [ 24000/60000]  loss: 0.47117543 \\ accuracy:  82.233%\n",
      "epoch:  2  batch:   50 [ 30000/60000]  loss: 0.39976367 \\ accuracy:  82.237%\n",
      "epoch:  2  batch:   60 [ 36000/60000]  loss: 0.48173201 \\ accuracy:  82.128%\n",
      "epoch:  2  batch:   70 [ 42000/60000]  loss: 0.52427250 \\ accuracy:  82.198%\n",
      "epoch:  2  batch:   80 [ 48000/60000]  loss: 0.42716160 \\ accuracy:  82.358%\n",
      "epoch:  2  batch:   90 [ 54000/60000]  loss: 0.49188334 \\ accuracy:  82.363%\n",
      "epoch:  2  batch:  100 [ 60000/60000]  loss: 0.47324762 \\ accuracy:  82.382%\n",
      "epoch:  3  batch:   10 [  6000/60000]  loss: 0.43640855 \\ accuracy:  84.250%\n",
      "epoch:  3  batch:   20 [ 12000/60000]  loss: 0.37779444 \\ accuracy:  83.842%\n",
      "epoch:  3  batch:   30 [ 18000/60000]  loss: 0.43300608 \\ accuracy:  83.722%\n",
      "epoch:  3  batch:   40 [ 24000/60000]  loss: 0.40782857 \\ accuracy:  83.775%\n",
      "epoch:  3  batch:   50 [ 30000/60000]  loss: 0.40419185 \\ accuracy:  83.833%\n",
      "epoch:  3  batch:   60 [ 36000/60000]  loss: 0.41699713 \\ accuracy:  83.808%\n",
      "epoch:  3  batch:   70 [ 42000/60000]  loss: 0.42459777 \\ accuracy:  83.993%\n",
      "epoch:  3  batch:   80 [ 48000/60000]  loss: 0.38359278 \\ accuracy:  83.969%\n",
      "epoch:  3  batch:   90 [ 54000/60000]  loss: 0.39841816 \\ accuracy:  84.044%\n",
      "epoch:  3  batch:  100 [ 60000/60000]  loss: 0.45355886 \\ accuracy:  84.052%\n",
      "epoch:  4  batch:   10 [  6000/60000]  loss: 0.42364293 \\ accuracy:  84.317%\n",
      "epoch:  4  batch:   20 [ 12000/60000]  loss: 0.41541350 \\ accuracy:  84.533%\n",
      "epoch:  4  batch:   30 [ 18000/60000]  loss: 0.38842008 \\ accuracy:  84.728%\n",
      "epoch:  4  batch:   40 [ 24000/60000]  loss: 0.36773029 \\ accuracy:  84.862%\n",
      "epoch:  4  batch:   50 [ 30000/60000]  loss: 0.42494571 \\ accuracy:  84.850%\n",
      "epoch:  4  batch:   60 [ 36000/60000]  loss: 0.33922911 \\ accuracy:  84.950%\n",
      "epoch:  4  batch:   70 [ 42000/60000]  loss: 0.35107949 \\ accuracy:  84.921%\n",
      "epoch:  4  batch:   80 [ 48000/60000]  loss: 0.45041907 \\ accuracy:  84.996%\n",
      "epoch:  4  batch:   90 [ 54000/60000]  loss: 0.37084773 \\ accuracy:  85.185%\n",
      "epoch:  4  batch:  100 [ 60000/60000]  loss: 0.44104615 \\ accuracy:  85.127%\n",
      "epoch:  5  batch:   10 [  6000/60000]  loss: 0.43115225 \\ accuracy:  85.900%\n",
      "epoch:  5  batch:   20 [ 12000/60000]  loss: 0.34788245 \\ accuracy:  86.042%\n",
      "epoch:  5  batch:   30 [ 18000/60000]  loss: 0.35348609 \\ accuracy:  85.933%\n",
      "epoch:  5  batch:   40 [ 24000/60000]  loss: 0.36843678 \\ accuracy:  85.846%\n",
      "epoch:  5  batch:   50 [ 30000/60000]  loss: 0.42430505 \\ accuracy:  85.773%\n",
      "epoch:  5  batch:   60 [ 36000/60000]  loss: 0.35708487 \\ accuracy:  85.844%\n",
      "epoch:  5  batch:   70 [ 42000/60000]  loss: 0.35760751 \\ accuracy:  85.717%\n",
      "epoch:  5  batch:   80 [ 48000/60000]  loss: 0.41135719 \\ accuracy:  85.723%\n",
      "epoch:  5  batch:   90 [ 54000/60000]  loss: 0.33067241 \\ accuracy:  85.824%\n",
      "epoch:  5  batch:  100 [ 60000/60000]  loss: 0.32855043 \\ accuracy:  85.778%\n",
      "epoch:  6  batch:   10 [  6000/60000]  loss: 0.40763587 \\ accuracy:  86.717%\n",
      "epoch:  6  batch:   20 [ 12000/60000]  loss: 0.35353532 \\ accuracy:  86.242%\n",
      "epoch:  6  batch:   30 [ 18000/60000]  loss: 0.36515072 \\ accuracy:  86.328%\n",
      "epoch:  6  batch:   40 [ 24000/60000]  loss: 0.45834619 \\ accuracy:  86.150%\n",
      "epoch:  6  batch:   50 [ 30000/60000]  loss: 0.38764650 \\ accuracy:  86.027%\n",
      "epoch:  6  batch:   60 [ 36000/60000]  loss: 0.38208145 \\ accuracy:  86.047%\n",
      "epoch:  6  batch:   70 [ 42000/60000]  loss: 0.36352769 \\ accuracy:  86.100%\n",
      "epoch:  6  batch:   80 [ 48000/60000]  loss: 0.34862956 \\ accuracy:  86.115%\n",
      "epoch:  6  batch:   90 [ 54000/60000]  loss: 0.36210695 \\ accuracy:  86.157%\n",
      "epoch:  6  batch:  100 [ 60000/60000]  loss: 0.37966025 \\ accuracy:  86.190%\n",
      "epoch:  7  batch:   10 [  6000/60000]  loss: 0.39412463 \\ accuracy:  86.283%\n",
      "epoch:  7  batch:   20 [ 12000/60000]  loss: 0.40391523 \\ accuracy:  86.408%\n",
      "epoch:  7  batch:   30 [ 18000/60000]  loss: 0.39135724 \\ accuracy:  86.783%\n",
      "epoch:  7  batch:   40 [ 24000/60000]  loss: 0.33335701 \\ accuracy:  86.817%\n",
      "epoch:  7  batch:   50 [ 30000/60000]  loss: 0.32229242 \\ accuracy:  87.083%\n",
      "epoch:  7  batch:   60 [ 36000/60000]  loss: 0.35845894 \\ accuracy:  86.917%\n",
      "epoch:  7  batch:   70 [ 42000/60000]  loss: 0.32867974 \\ accuracy:  86.886%\n",
      "epoch:  7  batch:   80 [ 48000/60000]  loss: 0.39204580 \\ accuracy:  86.773%\n",
      "epoch:  7  batch:   90 [ 54000/60000]  loss: 0.36592102 \\ accuracy:  86.791%\n",
      "epoch:  7  batch:  100 [ 60000/60000]  loss: 0.35228205 \\ accuracy:  86.750%\n",
      "epoch:  8  batch:   10 [  6000/60000]  loss: 0.37752628 \\ accuracy:  87.283%\n",
      "epoch:  8  batch:   20 [ 12000/60000]  loss: 0.35733166 \\ accuracy:  87.592%\n",
      "epoch:  8  batch:   30 [ 18000/60000]  loss: 0.36624095 \\ accuracy:  87.250%\n",
      "epoch:  8  batch:   40 [ 24000/60000]  loss: 0.37287530 \\ accuracy:  87.204%\n",
      "epoch:  8  batch:   50 [ 30000/60000]  loss: 0.38864750 \\ accuracy:  87.077%\n",
      "epoch:  8  batch:   60 [ 36000/60000]  loss: 0.36990154 \\ accuracy:  87.000%\n",
      "epoch:  8  batch:   70 [ 42000/60000]  loss: 0.31569195 \\ accuracy:  86.998%\n",
      "epoch:  8  batch:   80 [ 48000/60000]  loss: 0.33904707 \\ accuracy:  86.946%\n",
      "epoch:  8  batch:   90 [ 54000/60000]  loss: 0.27613389 \\ accuracy:  87.002%\n",
      "epoch:  8  batch:  100 [ 60000/60000]  loss: 0.38377997 \\ accuracy:  87.063%\n",
      "epoch:  9  batch:   10 [  6000/60000]  loss: 0.34896386 \\ accuracy:  88.317%\n",
      "epoch:  9  batch:   20 [ 12000/60000]  loss: 0.36187643 \\ accuracy:  87.825%\n",
      "epoch:  9  batch:   30 [ 18000/60000]  loss: 0.33662108 \\ accuracy:  87.872%\n",
      "epoch:  9  batch:   40 [ 24000/60000]  loss: 0.32477733 \\ accuracy:  87.912%\n",
      "epoch:  9  batch:   50 [ 30000/60000]  loss: 0.32014635 \\ accuracy:  87.897%\n",
      "epoch:  9  batch:   60 [ 36000/60000]  loss: 0.31229889 \\ accuracy:  87.597%\n",
      "epoch:  9  batch:   70 [ 42000/60000]  loss: 0.37614760 \\ accuracy:  87.467%\n",
      "epoch:  9  batch:   80 [ 48000/60000]  loss: 0.34079215 \\ accuracy:  87.515%\n",
      "epoch:  9  batch:   90 [ 54000/60000]  loss: 0.37605128 \\ accuracy:  87.578%\n",
      "epoch:  9  batch:  100 [ 60000/60000]  loss: 0.36080986 \\ accuracy:  87.562%\n",
      "\n",
      "Duration: 68 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "epochs = 10\n",
    "tanh_trn_losses = []\n",
    "tanh_tst_losses = []\n",
    "tanh_trn_correct = []\n",
    "tanh_tst_correct =[]\n",
    "\n",
    "for i in range(epochs):\n",
    "    \n",
    "    trn_corr = 0\n",
    "    tst_corr = 0\n",
    "    \n",
    "    for b, (X_train, y_train) in enumerate(train_loader):\n",
    "        b+=1\n",
    "        \n",
    "        y_pred = model_tanh_SM(X_train)\n",
    "        loss = tanh_SM_criterion(y_pred, y_train)\n",
    "        \n",
    "        predicted = torch.max(y_pred.data, 1)[1]\n",
    "        batch_corr = (predicted == y_train).sum()\n",
    "        trn_corr += batch_corr\n",
    "        \n",
    "        tanh_SM_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        tanh_SM_optimizer.step()\n",
    "        \n",
    "        if b%10 == 0:\n",
    "            print(f'epoch: {i:2}  batch: {b:4} [{600*b:6}/60000]  loss: {loss.item():10.8f} \\ accuracy: {trn_corr.item()*100/(600*b):7.3f}%')\n",
    "            \n",
    "    tanh_trn_losses.append(loss.item())\n",
    "    tanh_trn_correct.append(trn_corr.item())\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for b, (X_test, y_test) in enumerate(test_loader):\n",
    "            \n",
    "            y_val = model_tanh_SM(X_test)\n",
    "            \n",
    "            predicted = torch.max(y_val.data, 1)[1]\n",
    "            tst_corr += (predicted == y_test).sum()\n",
    "            \n",
    "    \n",
    "    loss = tanh_SM_criterion(y_val, y_test)\n",
    "    tanh_tst_losses.append(loss)\n",
    "    tanh_tst_correct.append(tst_corr)\n",
    "    \n",
    "\n",
    "print(f'\\nDuration: {time.time() - start_time:.0f} seconds') # print the time elapsed            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc19780",
   "metadata": {},
   "source": [
    "#### Time: 68 Seconds / Accuracy: 87.56%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6d848b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
